{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b076bd1a-b236-4fbc-953d-8295b25122ae",
   "metadata": {
    "id": "b076bd1a-b236-4fbc-953d-8295b25122ae"
   },
   "source": [
    "# ğŸ¥™ LSTM - ë ˆì‹œí”¼ ë°ì´í„°ì…‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5795b771",
   "metadata": {
    "id": "5795b771"
   },
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/rickiepark/Generative_Deep_Learning_2nd_Edition/blob/main/notebooks/05_autoregressive/01_lstm/lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658a95da-9645-4bcf-bd9d-4b95a4b6f582",
   "metadata": {
    "id": "658a95da-9645-4bcf-bd9d-4b95a4b6f582"
   },
   "source": [
    "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” ë ˆì‹œí”¼ ë°ì´í„°ì…‹ì—ì„œ LSTMì„ í›ˆë ¨í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e0d56cc-4773-4029-97d8-26f882ba79c9",
   "metadata": {
    "id": "4e0d56cc-4773-4029-97d8-26f882ba79c9"
   },
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import string\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks, losses"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "339e6268-ebd7-4feb-86db-1fe7abccdbe5",
   "metadata": {
    "id": "339e6268-ebd7-4feb-86db-1fe7abccdbe5"
   },
   "source": [
    "## 0. íŒŒë¼ë¯¸í„° <a name=\"parameters\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d8352af-343e-4c2e-8c91-95f8bac1c8a1",
   "metadata": {
    "id": "2d8352af-343e-4c2e-8c91-95f8bac1c8a1"
   },
   "source": [
    "VOCAB_SIZE = 10000\n",
    "MAX_LEN = 200\n",
    "EMBEDDING_DIM = 100\n",
    "N_UNITS = 128\n",
    "VALIDATION_SPLIT = 0.2\n",
    "SEED = 42\n",
    "LOAD_MODEL = False\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 25"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "b7716fac-0010-49b0-b98e-53be2259edde",
   "metadata": {
    "id": "b7716fac-0010-49b0-b98e-53be2259edde"
   },
   "source": [
    "## 1. ë°ì´í„° ë¡œë“œ <a name=\"load\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46881426",
   "metadata": {
    "id": "46881426",
    "outputId": "79d23b10-3e6c-4687-e250-d1ccb913203f",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 128
    }
   },
   "source": [
    "import sys\n",
    "\n",
    "# ì½”ë©ì¼ ê²½ìš° ë…¸íŠ¸ë¶ì—ì„œ celeba ë°ì´í„°ì…‹ì„ ë°›ìŠµë‹ˆë‹¤.\n",
    "if 'google.colab' in sys.modules:\n",
    "    # ìºê¸€-->Setttings-->API-->Create New Tokenì—ì„œ\n",
    "    # kaggle.json íŒŒì¼ì„ ë§Œë“¤ì–´ ì½”ë©ì— ì—…ë¡œë“œí•˜ì„¸ìš”.\n",
    "    from google.colab import files\n",
    "    files.upload()\n",
    "    !mkdir ~/.kaggle\n",
    "    !cp kaggle.json ~/.kaggle/\n",
    "    !chmod 600 ~/.kaggle/kaggle.json\n",
    "    # celeba ë°ì´í„°ì…‹ì„ ë‹¤ìš´ë¡œë“œí•˜ê³  ì••ì¶•ì„ í•´ì œí•©ë‹ˆë‹¤.\n",
    "    !kaggle datasets download -d hugodarwood/epirecipes\n",
    "    !unzip -q epirecipes.zip"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93cf6b0f-9667-4146-8911-763a8a2925d3",
   "metadata": {
    "tags": [],
    "id": "93cf6b0f-9667-4146-8911-763a8a2925d3"
   },
   "source": [
    "# ì „ì²´ ë°ì´í„°ì…‹ ë¡œë“œ\n",
    "with open(\"./full_format_recipes.json\") as json_data:\n",
    "    recipe_data = json.load(json_data)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23a74eca-f1b7-4a46-9a1f-b5806a4ed361",
   "metadata": {
    "tags": [],
    "id": "23a74eca-f1b7-4a46-9a1f-b5806a4ed361"
   },
   "source": [
    "# ë°ì´í„°ì…‹ í•„í„°ë§\n",
    "filtered_data = [\n",
    "    \"Recipe for \" + x[\"title\"] + \" | \" + \" \".join(x[\"directions\"])\n",
    "    for x in recipe_data\n",
    "    if \"title\" in x\n",
    "    and x[\"title\"] is not None\n",
    "    and \"directions\" in x\n",
    "    and x[\"directions\"] is not None\n",
    "]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "389c20de-0422-4c48-a7b4-6ee12a7bf0e2",
   "metadata": {
    "tags": [],
    "id": "389c20de-0422-4c48-a7b4-6ee12a7bf0e2",
    "outputId": "2661224e-3f06-44b3-fb7e-b1d61e728810",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "# ë ˆì‹œí”¼ ê°œìˆ˜ í™•ì¸\n",
    "n_recipes = len(filtered_data)\n",
    "print(f\"{n_recipes}ê°œ ë ˆì‹œí”¼ ë¡œë“œ\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b2e3cf7-e416-460e-874a-0dd9637bca36",
   "metadata": {
    "id": "1b2e3cf7-e416-460e-874a-0dd9637bca36",
    "outputId": "3d306c7a-1857-4faa-d232-60906e78ac7b",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "example = filtered_data[9]\n",
    "print(example)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "3f871aaf-d873-41c7-8946-e4eef7ac17c1",
   "metadata": {
    "id": "3f871aaf-d873-41c7-8946-e4eef7ac17c1"
   },
   "source": [
    "## 2. ë°ì´í„° í† í°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b2064fb-5dcc-4657-b470-0928d10e2ddc",
   "metadata": {
    "tags": [],
    "id": "5b2064fb-5dcc-4657-b470-0928d10e2ddc"
   },
   "source": [
    "# êµ¬ë‘ì ì„ ë¶„ë¦¬í•˜ì—¬ ë³„ë„ì˜ 'ë‹¨ì–´'ë¡œ ì·¨ê¸‰í•©ë‹ˆë‹¤.\n",
    "def pad_punctuation(s):\n",
    "    s = re.sub(f\"([{string.punctuation}])\", r\" \\1 \", s)\n",
    "    s = re.sub(\" +\", \" \", s)\n",
    "    return s\n",
    "\n",
    "\n",
    "text_data = [pad_punctuation(x) for x in filtered_data]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b87d7c65-9a46-492a-a5c0-a043b0d252f3",
   "metadata": {
    "id": "b87d7c65-9a46-492a-a5c0-a043b0d252f3",
    "outputId": "eef1c85e-8a2c-4750-d9f8-9a238ee75251",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    }
   },
   "source": [
    "# ë ˆì‹œí”¼ ìƒ˜í”Œ ì¶œë ¥\n",
    "example_data = text_data[9]\n",
    "example_data"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9834f916-b21a-4104-acc9-f28d3bd7a8c1",
   "metadata": {
    "tags": [],
    "id": "9834f916-b21a-4104-acc9-f28d3bd7a8c1"
   },
   "source": [
    "# í…ì„œí”Œë¡œ ë°ì´í„°ì…‹ìœ¼ë¡œ ë³€í™˜í•˜ê¸°\n",
    "text_ds = (\n",
    "    tf.data.Dataset.from_tensor_slices(text_data)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .shuffle(1000)\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "884c0bcb-0807-45a1-8f7e-a32f2c6fa4de",
   "metadata": {
    "id": "884c0bcb-0807-45a1-8f7e-a32f2c6fa4de"
   },
   "source": [
    "# ë²¡í„°í™” ì¸µ ë§Œë“¤ê¸°\n",
    "vectorize_layer = layers.TextVectorization(\n",
    "    standardize=\"lower\",\n",
    "    max_tokens=VOCAB_SIZE,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=MAX_LEN + 1,\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d6dd34a-d905-497b-926a-405380ebcf98",
   "metadata": {
    "id": "4d6dd34a-d905-497b-926a-405380ebcf98"
   },
   "source": [
    "# í›ˆë ¨ ì„¸íŠ¸ì— ì¸µ ì ìš©\n",
    "vectorize_layer.adapt(text_ds)\n",
    "vocab = vectorize_layer.get_vocabulary()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6c1c7ce-3cf0-40d4-a3dc-ab7090f69f2f",
   "metadata": {
    "id": "f6c1c7ce-3cf0-40d4-a3dc-ab7090f69f2f",
    "outputId": "959361a8-72b7-44da-a871-075ef0342fcc",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "# í† í°:ë‹¨ì–´ ë§¤í•‘ ìƒ˜í”Œ ì¶œë ¥í•˜ê¸°\n",
    "for i, word in enumerate(vocab[:10]):\n",
    "    print(f\"{i}: {word}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1cc30186-7ec6-4eb6-b29a-65df6714d321",
   "metadata": {
    "id": "1cc30186-7ec6-4eb6-b29a-65df6714d321",
    "outputId": "41e4a1ef-550f-4b17-a99e-cabc24182080",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "# ë™ì¼ ìƒ˜í”Œì„ ì •ìˆ˜ë¡œ ë³€í™˜í•˜ì—¬ ì¶œë ¥í•˜ê¸°\n",
    "example_tokenised = vectorize_layer(example_data)\n",
    "print(example_tokenised.numpy())"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "8c195efb-84c6-4be0-a989-a7542188ad35",
   "metadata": {
    "id": "8c195efb-84c6-4be0-a989-a7542188ad35"
   },
   "source": [
    "## 3. í›ˆë ¨ ì„¸íŠ¸ ë§Œë“¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "740294a1-1a6b-4c89-92f2-036d7d1b788b",
   "metadata": {
    "id": "740294a1-1a6b-4c89-92f2-036d7d1b788b"
   },
   "source": [
    "# ë ˆì‹œí”¼ì™€ í•œ ë‹¨ì–´ ì´ë™í•œ ë™ì¼ í…ìŠ¤íŠ¸ë¡œ í›ˆë ¨ ì„¸íŠ¸ë¥¼ ë§Œë“­ë‹ˆë‹¤.\n",
    "def prepare_inputs(text):\n",
    "    text = tf.expand_dims(text, -1)\n",
    "    tokenized_sentences = vectorize_layer(text)\n",
    "    x = tokenized_sentences[:, :-1]\n",
    "    y = tokenized_sentences[:, 1:]\n",
    "    return x, y\n",
    "\n",
    "\n",
    "train_ds = text_ds.map(prepare_inputs)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "aff50401-3abe-4c10-bba8-b35bc13ad7d5",
   "metadata": {
    "tags": [],
    "id": "aff50401-3abe-4c10-bba8-b35bc13ad7d5"
   },
   "source": [
    "## 4. LSTM ë§Œë“¤ê¸° <a name=\"build\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9230b5bf-b4a8-48d5-b73b-6899a598f296",
   "metadata": {
    "id": "9230b5bf-b4a8-48d5-b73b-6899a598f296",
    "outputId": "1ef24943-2fce-4c0b-d97a-449067e45da4",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "inputs = layers.Input(shape=(None,), dtype=\"int32\")\n",
    "x = layers.Embedding(VOCAB_SIZE, EMBEDDING_DIM)(inputs)\n",
    "x = layers.LSTM(N_UNITS, return_sequences=True)(x)\n",
    "outputs = layers.Dense(VOCAB_SIZE, activation=\"softmax\")(x)\n",
    "lstm = models.Model(inputs, outputs)\n",
    "lstm.summary()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "800a3c6e-fb11-4792-b6bc-9a43a7c977ad",
   "metadata": {
    "tags": [],
    "id": "800a3c6e-fb11-4792-b6bc-9a43a7c977ad"
   },
   "source": [
    "if LOAD_MODEL:\n",
    "    # model.load_weights('./models/model')\n",
    "    lstm = models.load_model(\"./models/lstm\", compile=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "35b14665-4359-447b-be58-3fd58ba69084",
   "metadata": {
    "id": "35b14665-4359-447b-be58-3fd58ba69084"
   },
   "source": [
    "## 5. LSTM í›ˆë ¨í•˜ê¸° <a name=\"train\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ffb1bd3b-6fd9-4536-973e-6375bbcbf16d",
   "metadata": {
    "id": "ffb1bd3b-6fd9-4536-973e-6375bbcbf16d"
   },
   "source": [
    "loss_fn = losses.SparseCategoricalCrossentropy()\n",
    "lstm.compile(\"adam\", loss_fn)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3ddcff5f-829d-4449-99d2-9a3cb68f7d72",
   "metadata": {
    "id": "3ddcff5f-829d-4449-99d2-9a3cb68f7d72"
   },
   "source": [
    "# TextGenerator ì²´í¬í¬ì¸íŠ¸ ë§Œë“¤ê¸°\n",
    "class TextGenerator(callbacks.Callback):\n",
    "    def __init__(self, index_to_word, top_k=10):\n",
    "        self.index_to_word = index_to_word\n",
    "        self.word_to_index = {\n",
    "            word: index for index, word in enumerate(index_to_word)\n",
    "        }\n",
    "\n",
    "    def sample_from(self, probs, temperature):\n",
    "        probs = probs ** (1 / temperature)\n",
    "        probs = probs / np.sum(probs)\n",
    "        return np.random.choice(len(probs), p=probs), probs\n",
    "\n",
    "    def generate(self, start_prompt, max_tokens, temperature):\n",
    "        start_tokens = [\n",
    "            self.word_to_index.get(x, 1) for x in start_prompt.split()\n",
    "        ]\n",
    "        sample_token = None\n",
    "        info = []\n",
    "        while len(start_tokens) < max_tokens and sample_token != 0:\n",
    "            x = np.array([start_tokens])\n",
    "            y = self.model.predict(x, verbose=0)\n",
    "            sample_token, probs = self.sample_from(y[0][-1], temperature)\n",
    "            info.append({\"prompt\": start_prompt, \"word_probs\": probs})\n",
    "            start_tokens.append(sample_token)\n",
    "            start_prompt = start_prompt + \" \" + self.index_to_word[sample_token]\n",
    "        print(f\"\\nìƒì„±ëœ í…ìŠ¤íŠ¸:\\n{start_prompt}\\n\")\n",
    "        return info\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.generate(\"recipe for\", max_tokens=100, temperature=1.0)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "349865fe-ffbe-450e-97be-043ae1740e78",
   "metadata": {
    "id": "349865fe-ffbe-450e-97be-043ae1740e78"
   },
   "source": [
    "# ëª¨ë¸ ì €ì¥ ì²´í¬í¬ì¸íŠ¸ ë§Œë“¤ê¸°\n",
    "model_checkpoint_callback = callbacks.ModelCheckpoint(\n",
    "    filepath=\"./checkpoint/checkpoint.ckpt\",\n",
    "    save_weights_only=True,\n",
    "    save_freq=\"epoch\",\n",
    "    verbose=0,\n",
    ")\n",
    "\n",
    "tensorboard_callback = callbacks.TensorBoard(log_dir=\"./logs\")\n",
    "\n",
    "# ì‹œì‘ í”„ë¡¬í”„íŠ¸ í† í°í™”\n",
    "text_generator = TextGenerator(vocab)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "461c2b3e-b5ae-4def-8bd9-e7bab8c63d8e",
   "metadata": {
    "tags": [],
    "id": "461c2b3e-b5ae-4def-8bd9-e7bab8c63d8e",
    "outputId": "1b942983-8580-4856-ac5a-51e823307cba",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "lstm.fit(\n",
    "    train_ds,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[model_checkpoint_callback, tensorboard_callback, text_generator],\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "369bde44-2e39-4bc6-8549-a3a27ecce55c",
   "metadata": {
    "tags": [],
    "id": "369bde44-2e39-4bc6-8549-a3a27ecce55c"
   },
   "source": [
    "# ìµœì¢… ëª¨ë¸ ì €ì¥\n",
    "lstm.save(\"./models/lstm\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "d64e02d2-84dc-40c8-8446-40c09adf1e20",
   "metadata": {
    "id": "d64e02d2-84dc-40c8-8446-40c09adf1e20"
   },
   "source": [
    "## 6. LSTMì„ ì‚¬ìš©í•´ í…ìŠ¤íŠ¸ ìƒì„±í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4ad23adb-3ec9-4e9a-9a59-b9f9bafca649",
   "metadata": {
    "id": "4ad23adb-3ec9-4e9a-9a59-b9f9bafca649"
   },
   "source": [
    "def print_probs(info, vocab, top_k=5):\n",
    "    for i in info:\n",
    "        print(f\"\\ní”„ë¡¬í”„íŠ¸: {i['prompt']}\")\n",
    "        word_probs = i[\"word_probs\"]\n",
    "        p_sorted = np.sort(word_probs)[::-1][:top_k]\n",
    "        i_sorted = np.argsort(word_probs)[::-1][:top_k]\n",
    "        for p, i in zip(p_sorted, i_sorted):\n",
    "            print(f\"{vocab[i]}:   \\t{np.round(100*p,2)}%\")\n",
    "        print(\"--------\\n\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3cf25578-d47c-4b26-8252-fcdf2316a4ac",
   "metadata": {
    "id": "3cf25578-d47c-4b26-8252-fcdf2316a4ac",
    "outputId": "a0bff77e-69fd-481e-ad67-365a1c3cbc48",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "info = text_generator.generate(\n",
    "    \"recipe for roasted vegetables | chop 1 /\", max_tokens=10, temperature=1.0\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9df72866-b483-4489-8e26-d5e1466410fa",
   "metadata": {
    "tags": [],
    "id": "9df72866-b483-4489-8e26-d5e1466410fa",
    "outputId": "88bfc6d8-f838-4cdd-b68d-22f0574b06a8",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "print_probs(info, vocab)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "562e1fe8-cbcb-438f-9637-2f2a6279c924",
   "metadata": {
    "id": "562e1fe8-cbcb-438f-9637-2f2a6279c924",
    "outputId": "6538dfbc-8692-4c4d-d110-51e75ff87175",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "info = text_generator.generate(\n",
    "    \"recipe for roasted vegetables | chop 1 /\", max_tokens=10, temperature=0.2\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "56356f21-04ac-40e5-94ff-291eca6a7054",
   "metadata": {
    "id": "56356f21-04ac-40e5-94ff-291eca6a7054",
    "outputId": "e3d179c3-69a2-4206-bf85-f02a80509c55",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "print_probs(info, vocab)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2e434497-07f3-4989-a68d-3e31cf8fa4fe",
   "metadata": {
    "id": "2e434497-07f3-4989-a68d-3e31cf8fa4fe",
    "outputId": "8bf7d28d-931d-43f3-b5ba-d3cd7b0522a1",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "info = text_generator.generate(\n",
    "    \"recipe for chocolate ice cream |\", max_tokens=7, temperature=1.0\n",
    ")\n",
    "print_probs(info, vocab)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "011cd0e0-956c-4a63-8ec3-f7dfed31764e",
   "metadata": {
    "id": "011cd0e0-956c-4a63-8ec3-f7dfed31764e",
    "outputId": "70df0595-39c4-4107-c202-da5e41aaa90c",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "info = text_generator.generate(\n",
    "    \"recipe for chocolate ice cream |\", max_tokens=7, temperature=0.2\n",
    ")\n",
    "print_probs(info, vocab)"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
