{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b076bd1a-b236-4fbc-953d-8295b25122ae",
   "metadata": {
    "id": "b076bd1a-b236-4fbc-953d-8295b25122ae"
   },
   "source": [
    "# 🧱 DCGAN - 블록 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ad1b96",
   "metadata": {
    "id": "69ad1b96"
   },
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/rickiepark/Generative_Deep_Learning_2nd_Edition/blob/main/notebooks/04_gan/01_dcgan/dcgan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d89c2d6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6d89c2d6",
    "outputId": "424c01b6-b857-47f1-837e-faa7d32cb38f"
   },
   "source": [
    "import sys\n",
    "\n",
    "# 코랩의 경우 깃허브 저장소로부터 utils.py를 다운로드 합니다.\n",
    "if 'google.colab' in sys.modules:\n",
    "    !wget https://raw.githubusercontent.com/rickiepark/Generative_Deep_Learning_2nd_Edition/main/notebooks/utils.py\n",
    "    !mkdir -p notebooks\n",
    "    !mv utils.py notebooks"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "1603ea4b-8345-4e2e-ae7c-01c9953900e8",
   "metadata": {
    "id": "1603ea4b-8345-4e2e-ae7c-01c9953900e8"
   },
   "source": [
    "이 노트북에서는 레고 블록 데이터셋에서 DCGAN을 훈련합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e0d56cc-4773-4029-97d8-26f882ba79c9",
   "metadata": {
    "id": "4e0d56cc-4773-4029-97d8-26f882ba79c9"
   },
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import (\n",
    "    layers,\n",
    "    models,\n",
    "    callbacks,\n",
    "    losses,\n",
    "    utils,\n",
    "    metrics,\n",
    "    optimizers,\n",
    ")\n",
    "\n",
    "from notebooks.utils import display, sample_batch"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "339e6268-ebd7-4feb-86db-1fe7abccdbe5",
   "metadata": {
    "id": "339e6268-ebd7-4feb-86db-1fe7abccdbe5"
   },
   "source": [
    "## 0. 파라미터 <a name=\"parameters\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b2ee6ce-129f-4833-b0c5-fa567381c4e0",
   "metadata": {
    "id": "1b2ee6ce-129f-4833-b0c5-fa567381c4e0"
   },
   "source": [
    "IMAGE_SIZE = 64\n",
    "CHANNELS = 1\n",
    "BATCH_SIZE = 128\n",
    "Z_DIM = 100\n",
    "EPOCHS = 100 # 훈련이 오래 걸려 에포크 횟수를 300에서 100으로 줄입니다.\n",
    "LOAD_MODEL = False\n",
    "ADAM_BETA_1 = 0.5\n",
    "ADAM_BETA_2 = 0.999\n",
    "LEARNING_RATE = 0.0002\n",
    "NOISE_PARAM = 0.1"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "b7716fac-0010-49b0-b98e-53be2259edde",
   "metadata": {
    "id": "b7716fac-0010-49b0-b98e-53be2259edde"
   },
   "source": [
    "## 1. 데이터 준비 <a name=\"prepare\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "nDvX4kujaQMQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nDvX4kujaQMQ",
    "outputId": "1f259148-3df9-49f0-f6dc-ac5acff21265"
   },
   "source": [
    "# 코랩일 경우 노트북에서 celeba 데이터셋을 받습니다.\n",
    "if 'google.colab' in sys.modules:\n",
    "    # # 캐글-->Setttings-->API-->Create New Token에서\n",
    "    # # kaggle.json 파일을 만들어 코랩에 업로드하세요.\n",
    "    # from google.colab import files\n",
    "    # files.upload()\n",
    "    # !mkdir ~/.kaggle\n",
    "    # !cp kaggle.json ~/.kaggle/\n",
    "    # !chmod 600 ~/.kaggle/kaggle.json\n",
    "    # # celeba 데이터셋을 다운로드하고 압축을 해제합니다.\n",
    "    # !kaggle datasets download -d joosthazelzet/lego-brick-images\n",
    "    #\n",
    "    # 캐글에서 다운로드가 안 될 경우 역자의 드라이브에서 다운로드할 수 있습니다.\n",
    "    import gdown\n",
    "    gdown.download(id='1qd50QDZtr_NYFiFVdp0sIvGDwTT3mMEQ')\n",
    "    !unzip -q lego-brick-images.zip\n",
    "    # output 디렉토리를 만듭니다.\n",
    "    !mkdir output"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73f4c594-3f6d-4c8e-94c1-2c2ba7bce076",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "73f4c594-3f6d-4c8e-94c1-2c2ba7bce076",
    "outputId": "57e22660-b188-46e6-d054-3474cd1a6724"
   },
   "source": [
    "train_data = utils.image_dataset_from_directory(\n",
    "    \"./dataset/\",\n",
    "    labels=None,\n",
    "    color_mode=\"grayscale\",\n",
    "    image_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    interpolation=\"bilinear\",\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a995473f-c389-4158-92d2-93a2fa937916",
   "metadata": {
    "id": "a995473f-c389-4158-92d2-93a2fa937916"
   },
   "source": [
    "def preprocess(img):\n",
    "    \"\"\"\n",
    "    이미지 정규화 및 크기 변경\n",
    "    \"\"\"\n",
    "    img = (tf.cast(img, \"float32\") - 127.5) / 127.5\n",
    "    return img\n",
    "\n",
    "\n",
    "train = train_data.map(lambda x: preprocess(x))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80bcdbdd-fb1e-451f-b89c-03fd9b80deb5",
   "metadata": {
    "id": "80bcdbdd-fb1e-451f-b89c-03fd9b80deb5"
   },
   "source": [
    "train_sample = sample_batch(train)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa53709f-7f3f-483b-9db8-2e5f9b9942c2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 128
    },
    "id": "fa53709f-7f3f-483b-9db8-2e5f9b9942c2",
    "outputId": "bc25d865-ee2a-4f42-f6f5-6b1b05c60fca"
   },
   "source": [
    "display(train_sample)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "aff50401-3abe-4c10-bba8-b35bc13ad7d5",
   "metadata": {
    "id": "aff50401-3abe-4c10-bba8-b35bc13ad7d5",
    "tags": []
   },
   "source": [
    "## 2. GAN 구축 <a name=\"build\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9230b5bf-b4a8-48d5-b73b-6899a598f296",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9230b5bf-b4a8-48d5-b73b-6899a598f296",
    "outputId": "9e268300-f6a9-48e5-fde6-249c600f5ed8"
   },
   "source": [
    "discriminator_input = layers.Input(shape=(IMAGE_SIZE, IMAGE_SIZE, CHANNELS))\n",
    "x = layers.Conv2D(64, kernel_size=4, strides=2, padding=\"same\", use_bias=False)(\n",
    "    discriminator_input\n",
    ")\n",
    "x = layers.LeakyReLU(0.2)(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "x = layers.Conv2D(\n",
    "    128, kernel_size=4, strides=2, padding=\"same\", use_bias=False\n",
    ")(x)\n",
    "x = layers.BatchNormalization(momentum=0.9)(x)\n",
    "x = layers.LeakyReLU(0.2)(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "x = layers.Conv2D(\n",
    "    256, kernel_size=4, strides=2, padding=\"same\", use_bias=False\n",
    ")(x)\n",
    "x = layers.BatchNormalization(momentum=0.9)(x)\n",
    "x = layers.LeakyReLU(0.2)(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "x = layers.Conv2D(\n",
    "    512, kernel_size=4, strides=2, padding=\"same\", use_bias=False\n",
    ")(x)\n",
    "x = layers.BatchNormalization(momentum=0.9)(x)\n",
    "x = layers.LeakyReLU(0.2)(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "x = layers.Conv2D(\n",
    "    1,\n",
    "    kernel_size=4,\n",
    "    strides=1,\n",
    "    padding=\"valid\",\n",
    "    use_bias=False,\n",
    "    activation=\"sigmoid\",\n",
    ")(x)\n",
    "discriminator_output = layers.Flatten()(x)\n",
    "\n",
    "discriminator = models.Model(discriminator_input, discriminator_output)\n",
    "discriminator.summary()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b30dcc08-3869-4b67-a295-61f13d5d4e4c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b30dcc08-3869-4b67-a295-61f13d5d4e4c",
    "outputId": "0f636b5d-52e0-4705-bfc1-3e6e18bfcbcb"
   },
   "source": [
    "generator_input = layers.Input(shape=(Z_DIM,))\n",
    "x = layers.Reshape((1, 1, Z_DIM))(generator_input)\n",
    "x = layers.Conv2DTranspose(\n",
    "    512, kernel_size=4, strides=1, padding=\"valid\", use_bias=False\n",
    ")(x)\n",
    "x = layers.BatchNormalization(momentum=0.9)(x)\n",
    "x = layers.LeakyReLU(0.2)(x)\n",
    "x = layers.Conv2DTranspose(\n",
    "    256, kernel_size=4, strides=2, padding=\"same\", use_bias=False\n",
    ")(x)\n",
    "x = layers.BatchNormalization(momentum=0.9)(x)\n",
    "x = layers.LeakyReLU(0.2)(x)\n",
    "x = layers.Conv2DTranspose(\n",
    "    128, kernel_size=4, strides=2, padding=\"same\", use_bias=False\n",
    ")(x)\n",
    "x = layers.BatchNormalization(momentum=0.9)(x)\n",
    "x = layers.LeakyReLU(0.2)(x)\n",
    "x = layers.Conv2DTranspose(\n",
    "    64, kernel_size=4, strides=2, padding=\"same\", use_bias=False\n",
    ")(x)\n",
    "x = layers.BatchNormalization(momentum=0.9)(x)\n",
    "x = layers.LeakyReLU(0.2)(x)\n",
    "generator_output = layers.Conv2DTranspose(\n",
    "    CHANNELS,\n",
    "    kernel_size=4,\n",
    "    strides=2,\n",
    "    padding=\"same\",\n",
    "    use_bias=False,\n",
    "    activation=\"tanh\",\n",
    ")(x)\n",
    "generator = models.Model(generator_input, generator_output)\n",
    "generator.summary()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed493725-488b-4390-8c64-661f3b97a632",
   "metadata": {
    "id": "ed493725-488b-4390-8c64-661f3b97a632",
    "tags": []
   },
   "source": [
    "class DCGAN(models.Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        super(DCGAN, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer):\n",
    "        super(DCGAN, self).compile()\n",
    "        self.loss_fn = losses.BinaryCrossentropy()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.d_loss_metric = metrics.Mean(name=\"d_loss\")\n",
    "        self.d_real_acc_metric = metrics.BinaryAccuracy(name=\"d_real_acc\")\n",
    "        self.d_fake_acc_metric = metrics.BinaryAccuracy(name=\"d_fake_acc\")\n",
    "        self.d_acc_metric = metrics.BinaryAccuracy(name=\"d_acc\")\n",
    "        self.g_loss_metric = metrics.Mean(name=\"g_loss\")\n",
    "        self.g_acc_metric = metrics.BinaryAccuracy(name=\"g_acc\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.d_loss_metric,\n",
    "            self.d_real_acc_metric,\n",
    "            self.d_fake_acc_metric,\n",
    "            self.d_acc_metric,\n",
    "            self.g_loss_metric,\n",
    "            self.g_acc_metric,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, real_images):\n",
    "        # 잠재 공간에서 랜덤 포인트 샘플링\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        random_latent_vectors = tf.random.normal(\n",
    "            shape=(batch_size, self.latent_dim)\n",
    "        )\n",
    "\n",
    "        # 가짜 이미지로 판별자 훈련하기\n",
    "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "            generated_images = self.generator(\n",
    "                random_latent_vectors, training=True\n",
    "            )\n",
    "            real_predictions = self.discriminator(real_images, training=True)\n",
    "            fake_predictions = self.discriminator(\n",
    "                generated_images, training=True\n",
    "            )\n",
    "\n",
    "            real_labels = tf.ones_like(real_predictions)\n",
    "            real_noisy_labels = real_labels + NOISE_PARAM * tf.random.uniform(\n",
    "                tf.shape(real_predictions)\n",
    "            )\n",
    "            fake_labels = tf.zeros_like(fake_predictions)\n",
    "            fake_noisy_labels = fake_labels - NOISE_PARAM * tf.random.uniform(\n",
    "                tf.shape(fake_predictions)\n",
    "            )\n",
    "\n",
    "            d_real_loss = self.loss_fn(real_noisy_labels, real_predictions)\n",
    "            d_fake_loss = self.loss_fn(fake_noisy_labels, fake_predictions)\n",
    "            d_loss = (d_real_loss + d_fake_loss) / 2.0\n",
    "\n",
    "            g_loss = self.loss_fn(real_labels, fake_predictions)\n",
    "\n",
    "        gradients_of_discriminator = disc_tape.gradient(\n",
    "            d_loss, self.discriminator.trainable_variables\n",
    "        )\n",
    "        gradients_of_generator = gen_tape.gradient(\n",
    "            g_loss, self.generator.trainable_variables\n",
    "        )\n",
    "\n",
    "        self.d_optimizer.apply_gradients(\n",
    "            zip(gradients_of_discriminator, discriminator.trainable_variables)\n",
    "        )\n",
    "        self.g_optimizer.apply_gradients(\n",
    "            zip(gradients_of_generator, generator.trainable_variables)\n",
    "        )\n",
    "\n",
    "        # 메트릭 업데이트\n",
    "        self.d_loss_metric.update_state(d_loss)\n",
    "        self.d_real_acc_metric.update_state(real_labels, real_predictions)\n",
    "        self.d_fake_acc_metric.update_state(fake_labels, fake_predictions)\n",
    "        self.d_acc_metric.update_state(\n",
    "            [real_labels, fake_labels], [real_predictions, fake_predictions]\n",
    "        )\n",
    "        self.g_loss_metric.update_state(g_loss)\n",
    "        self.g_acc_metric.update_state(real_labels, fake_predictions)\n",
    "\n",
    "        return {m.name: m.result() for m in self.metrics}"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e898dd8e-f562-4517-8351-fc2f8b617a24",
   "metadata": {
    "id": "e898dd8e-f562-4517-8351-fc2f8b617a24"
   },
   "source": [
    "# DCGAN 생성\n",
    "dcgan = DCGAN(\n",
    "    discriminator=discriminator, generator=generator, latent_dim=Z_DIM\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "800a3c6e-fb11-4792-b6bc-9a43a7c977ad",
   "metadata": {
    "id": "800a3c6e-fb11-4792-b6bc-9a43a7c977ad"
   },
   "source": [
    "if LOAD_MODEL:\n",
    "    dcgan.load_weights(\"./checkpoint/checkpoint.ckpt\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "35b14665-4359-447b-be58-3fd58ba69084",
   "metadata": {
    "id": "35b14665-4359-447b-be58-3fd58ba69084"
   },
   "source": [
    "## 3. GAN 훈련 <a name=\"train\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "245e6374-5f5b-4efa-be0a-07b182f82d2d",
   "metadata": {
    "id": "245e6374-5f5b-4efa-be0a-07b182f82d2d"
   },
   "source": [
    "dcgan.compile(\n",
    "    d_optimizer=optimizers.Adam(\n",
    "        learning_rate=LEARNING_RATE, beta_1=ADAM_BETA_1, beta_2=ADAM_BETA_2\n",
    "    ),\n",
    "    g_optimizer=optimizers.Adam(\n",
    "        learning_rate=LEARNING_RATE, beta_1=ADAM_BETA_1, beta_2=ADAM_BETA_2\n",
    "    ),\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "349865fe-ffbe-450e-97be-043ae1740e78",
   "metadata": {
    "id": "349865fe-ffbe-450e-97be-043ae1740e78"
   },
   "source": [
    "# 모델 저장 체크포인트 만들기\n",
    "model_checkpoint_callback = callbacks.ModelCheckpoint(\n",
    "    filepath=\"./checkpoint/checkpoint.ckpt\",\n",
    "    save_weights_only=True,\n",
    "    save_freq=\"epoch\",\n",
    "    verbose=0,\n",
    ")\n",
    "\n",
    "tensorboard_callback = callbacks.TensorBoard(log_dir=\"./logs\")\n",
    "\n",
    "\n",
    "class ImageGenerator(callbacks.Callback):\n",
    "    def __init__(self, num_img, latent_dim):\n",
    "        self.num_img = num_img\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch % 10 == 0: # 출력 횟수를 줄이기 위해\n",
    "            random_latent_vectors = tf.random.normal(\n",
    "                shape=(self.num_img, self.latent_dim)\n",
    "            )\n",
    "            generated_images = self.model.generator(random_latent_vectors)\n",
    "            generated_images = generated_images * 127.5 + 127.5\n",
    "            generated_images = generated_images.numpy()\n",
    "            display(\n",
    "                generated_images,\n",
    "                save_to=\"./output/generated_img_%03d.png\" % (epoch),\n",
    "            )"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8913a77-f472-4008-9039-dba00e6db980",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "a8913a77-f472-4008-9039-dba00e6db980",
    "outputId": "4e02602b-8551-411f-f0aa-f7b67173188d",
    "tags": []
   },
   "source": [
    "dcgan.fit(\n",
    "    train,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[\n",
    "        model_checkpoint_callback,\n",
    "        tensorboard_callback,\n",
    "        ImageGenerator(num_img=10, latent_dim=Z_DIM),\n",
    "    ],\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "369bde44-2e39-4bc6-8549-a3a27ecce55c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "369bde44-2e39-4bc6-8549-a3a27ecce55c",
    "outputId": "2f812885-082a-4b79-fd89-c1d864f2ecb0"
   },
   "source": [
    "# 최종 모델 저장\n",
    "generator.save(\"./models/generator\")\n",
    "discriminator.save(\"./models/discriminator\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "26999087-0e85-4ddf-ba5f-13036466fce7",
   "metadata": {
    "id": "26999087-0e85-4ddf-ba5f-13036466fce7"
   },
   "source": [
    "## 3. 새로운 이미지 생성 <a name=\"decode\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48e90117-2e0e-4f4b-9138-b25dce9870f6",
   "metadata": {
    "id": "48e90117-2e0e-4f4b-9138-b25dce9870f6"
   },
   "source": [
    "# 표준 정규 분포에서 잠재 공간의 일부 포인트를 샘플링합니다.\n",
    "grid_width, grid_height = (10, 3)\n",
    "z_sample = np.random.normal(size=(grid_width * grid_height, Z_DIM))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e185509-3861-425c-882d-4fe16d82d355",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2e185509-3861-425c-882d-4fe16d82d355",
    "outputId": "7393e45f-a901-4c43-f6af-bda780276e93"
   },
   "source": [
    "# 샘플링된 포인트 디코딩\n",
    "reconstructions = generator.predict(z_sample)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e5e43c0-ef06-4d32-acf6-09f00cf2fa9c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 348
    },
    "id": "5e5e43c0-ef06-4d32-acf6-09f00cf2fa9c",
    "outputId": "b240eff7-6d7c-4125-bda6-b875678f2154"
   },
   "source": [
    "# 디코딩된 이미지 그리기\n",
    "fig = plt.figure(figsize=(18, 5))\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "# 얼굴 그리드 출력\n",
    "for i in range(grid_width * grid_height):\n",
    "    ax = fig.add_subplot(grid_height, grid_width, i + 1)\n",
    "    ax.axis(\"off\")\n",
    "    ax.imshow(reconstructions[i, :, :], cmap=\"Greys\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "59bfd4e4-7fdc-488a-86df-2c131c904803",
   "metadata": {
    "id": "59bfd4e4-7fdc-488a-86df-2c131c904803"
   },
   "source": [
    "def compare_images(img1, img2):\n",
    "    return np.mean(np.abs(img1 - img2))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b568995a-d4ad-478c-98b2-d9a1cdb9e841",
   "metadata": {
    "id": "b568995a-d4ad-478c-98b2-d9a1cdb9e841"
   },
   "source": [
    "all_data = []\n",
    "for i in train.as_numpy_iterator():\n",
    "    all_data.extend(i)\n",
    "all_data = np.array(all_data)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7c4b5bb1-3581-49b3-81ce-920400d6f3f7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 575
    },
    "id": "7c4b5bb1-3581-49b3-81ce-920400d6f3f7",
    "outputId": "9d64afff-8ff9-4f6b-a624-0426f7bcc564"
   },
   "source": [
    "r, c = 3, 5\n",
    "fig, axs = plt.subplots(r, c, figsize=(10, 6))\n",
    "fig.suptitle(\"Generated images\", fontsize=20)\n",
    "\n",
    "noise = np.random.normal(size=(r * c, Z_DIM))\n",
    "gen_imgs = generator.predict(noise)\n",
    "\n",
    "cnt = 0\n",
    "for i in range(r):\n",
    "    for j in range(c):\n",
    "        axs[i, j].imshow(gen_imgs[cnt], cmap=\"gray_r\")\n",
    "        axs[i, j].axis(\"off\")\n",
    "        cnt += 1\n",
    "\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "51923e98-bf0e-4de4-948a-05147c486b72",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 557
    },
    "id": "51923e98-bf0e-4de4-948a-05147c486b72",
    "outputId": "d25fb7c0-6637-46ff-9b93-80285414bc45"
   },
   "source": [
    "fig, axs = plt.subplots(r, c, figsize=(10, 6))\n",
    "fig.suptitle(\"Closest images in the training set\", fontsize=20)\n",
    "\n",
    "cnt = 0\n",
    "for i in range(r):\n",
    "    for j in range(c):\n",
    "        c_diff = 99999\n",
    "        c_img = None\n",
    "        for k_idx, k in enumerate(all_data):\n",
    "            diff = compare_images(gen_imgs[cnt], k)\n",
    "            if diff < c_diff:\n",
    "                c_img = np.copy(k)\n",
    "                c_diff = diff\n",
    "        axs[i, j].imshow(c_img, cmap=\"gray_r\")\n",
    "        axs[i, j].axis(\"off\")\n",
    "        cnt += 1\n",
    "\n",
    "plt.show()"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
