확산은 열역학의 확산에서 모티브를 따옴
점수 기반 생성모델?
잡음 조건부 점수 네트워크(NCSN)
잡음 제거 확산 확률 모델?(DDPM)

250p
8장은 잡음 제거 확산 모델의 작동 방식을 설명 및 코딩하는 장이라고 한다.

252p
잡음 제거 확산 모델의 발상은 연속해서 이미지에서
잡음을 제거하도록 딥러닝 모델을 훈련

완전히 랜덤한 잡음에서 시작해서
훈련 세트에서 가져온 것처럼 보이는 이미지를 가져오는것

253p
정방향 확산(잡음 추가) / 역방향 확산(잡음 제거)

정방향 확산의 목표는 이미지 x_0를 점진적으로 손상시켜
표준 가우스 잡음과 구분할 수 없도록 만드는것이다.
(x_T의 평균이 0, 분산이 1 즉 단위 분산)

이미지 x_t-1에 분산 Β_t를 갖는
소량의 가우스 잡음을 추가하여
새로운 이미지 x_t를 생성하는 함수 q를 정의한다.
이를 반복하면 원본 이미지 x_0는 잡음으로 가득한 x_T가 된다

※ 단위 분산: 분산이 1인것
https://blog.naver.com/magnking/221164336924
표준화 과정을 통해
표준화는 x' = (x - x_hat) / σ 의 공식을 사용하면된다

※※ 또 헷갈리는 정규화 표준화 스케일링 등등
https://heeya-stupidbutstudying.tistory.com/entry/%ED%86%B5%EA%B3%84-%EC%A0%95%EA%B7%9C%ED%99%94%EC%99%80-%ED%91%9C%EC%A4%80%ED%99%94
https://sebastianraschka.com/Articles/2014_about_feature_scaling.html#about-standardization
https://en.wikipedia.org/wiki/Normalization_(statistics)
정규화: 정규적인 상태로 만드는것
표준화: 표준 정규분포를 따르도록 만드는것

254p
정방향 확산 과정의 수학적 표현을 한다면
x_t = sqrt(1-B_t) * x_t-1 + sqrt(B_t) * ε_t-1

ε_t-1: 평균이 0이고 단위 분산을 갖는 표준 정규 분포
x_t: 함수 q(x_t|x_t-1)이후의 이미지
x_t-1: 위 함수에 입력하기전의 이미지
B_t: 추가할 노이즈의 분산

입력 이미지 x_t-1의 스케일도 조정하여
출력 이미지 x_t의 분산을 일정하게 만든다
x_0을 평균이 0이고 단위 분산을 갖도록 정규화하면서 진행한다면,
T가 클 때 x_T는 표준 가우스 분포에 가까울 것

x_t-1의 평균이 0이고 단위 분산을 갖는다면(즉, 과정 이전의 이미지의 값이 가우스 분포를 따른다면)
Var(aX) = a^2 * Var(X)의 공식을 따라(어느 값에 다른 값을 곱한것의 분산은 어느 값의 분산에 다른 값의 제곱을 곱한것???)
Var(sqrt(1-B_t) * x_t-1) = (1-B_t) * Var(x_t-1),
Var(sqrt(B_t) * ε_t-1) = B_t * Var(ε_t-1)

독립적인 X, Y에 대해 Var(X + Y) = Var(X) + Var(Y)
(두 집단간의 분산의 합은 두 집단을 합친 것의 분산과 같다
https://ko.khanacademy.org/math/statistics-probability/random-variables-stats-library/combine-random-variables/a/combining-random-variables-article
???????
통계학적인 베이스가 필요
따라서 정방향 확산 함수에서, 분산은 1-B_t+B_t = 1
즉 단위 분산으로 유지된다
평균은 x_t-1이나 ε_t-1이나 0이므로 더해도 평균은 0이다
즉 함수 q를 거친 이미지 x_t-1은,
잡음이 추가되었으되 여전히 표준 정규 분포를 따르는 새로운 이미지 x_t로 거듭난다

x_0가 평균이 0이고 단위 분산이 되도록 정규화 되었다면,
최종 이미지 x_T를 포함해 모든 x_t도 표준 정규 분포를 따른다
그것이 어떤 이점을 가저오는가?
x_T를 간단히 샘플링하고(왜나하면, 표준 정규 분포를 따를테니까)
역방향 확산에 넣을 수 있다

정방향 잡음 추가 과정 q는 수학적으로 다음과 같이 나타낼 수 있다.
q(x_t|x_t-1) = N(x_t; (1-B_t)^0.5 * x_t-1, B_t * I)

※   다음 URL http://taewan.kim/post/function_in_semicolon/
    에 따르면 함수에서 ;은 변수와 파라미터를 구분할 때 사용한다
※※ N은 그리스문자 뉴인지 영어엔인지 구분이 안간다, 책에는 필기체?로 그려져있음
x_t: q함수의 출력
x_t-1: q함수에 입력으로 들어가는 이미지
B_t: 추가될 노이즈의 분산
I: 단위행렬(= 표준 정규 분포를 따르는 공분산행렬)


255p
재매개변수화 트릭
함수 q를 t번 적용하면 이미지 x_0가 x_t가 되지만, 재매개변수화 트릭을 이용해
잡음이 있는 버전 x_t로 건너 뛸 수 있다고 한다.

a_t = 1 - B_t이
a_t_bar = Π_product(from i=1, to t, a_i)
(a_t_bar는 a_1부터 a_t까지 모든 a_i의 곱)
으로 정의하면
x_t는 다음과 같이 표현할 수 있다
x_t = sqrt(1-B_t) * x_t-1 + sqrt(B_t) * ε_t-1
    = sqrt(a_t) * x_t-1 + sqrt(1-a_t) * ε_t-1
    = sqrt(a_t) * (sqrt(a_t-1) * x_t-2 + sqrt(1 - a_t-1) * ε_t-2) + sqrt(1-a_t) * ε_t-1
    = sqrt(a_t * a_t-1) * x_t-2 + sqrt(a_t) * sqrt(1 - a_t-1) * ε_t-2 + sqrt(1-a_t) * ε_t-1
    = sqrt(a_t * a_t-1) * x_t-2 + sqrt(a_t * (1 - a_t-1) + 1 - a_t) * ε
    = sqrt(a_t * a_t-1) * x_t-2 + sqrt(a_t - a_t*a_t-1 + 1 - a_t) * ε
    = sqrt(a_t * a_t-1) * x_t-2 + sqrt(1 - a_t*a_t-1) * ε
    = sqrt(a_t * a_t-1 * a_t-2) * x_t-3 + sqrt(1 - a_t * a_t-1 * a_t-2) * ε
    = ⋯
    = sqrt(a_t_bar) * x_0 + sqrt(1 - a_t_bar) * ε

위 식에서, 4번째 줄의 ε_t-2과 ε_t-1는 각기 달리 나온 가우스 분포이나,
https://m.blog.naver.com/ljhjh123/130146586884
정규 분포의 성질에 의해 두 개의 가우스 분포를 더하여 새로운 가우스 분포를 얻을 수 있으며 이는 ε로 표현되었다.
※ 정규 분포의 가법성: 정규 분포끼리의 합/곱은 모두 정규 분포를 따른다
※※ 정규 분포의 가법성에 따라 독립인 두 확률 변수 X ~ N(μ_x, σ_x^2), Y ~ N(μ_y, σ_y^2)를 더하면 Z ~ N(μ_x + μ_y, σ_x^2 + σ_y^2)가 된다.
x_t-1를 재귀적으로 x_t-2에 대한 식으로 바꾼것이 2번째줄에서 3번째줄로 넘어갈 때 이루어졌다
이후 재귀적으로 사용하여 a_t_bar를 만들어내었다.

결론적으로 정방향 확산 과정 q는 다음과 같이 쓸 수 있으며
q(x_t|x_0) = N(x_t; sqrt(a_t_bar) * x_0, sqrt(1 - a_t_bar) * I)
B_t대신 a_t_bar 값을 사용해 확산 스케줄을 정의할 수 있다.
이 때, a_t_bar은 원본 이미지(= 신호)의 분산이고 1 - a_t_bar는 잡음(= ε)으로 인한 분산이다

(??? 잡음도 다변량 표준 정규 분포에서 왔을테니 공분산 행렬 I를 쓰는것인가?)
(???? a_t_bar나 B_t는 원본과 잡음의 비율, 스케일링도해주는것인가?)

찐 결론은, 잡음 추가 단계는 스킵을 할 수가 있다는 것이다.

256p
a_t_bar나 B_t는 각 단계에서 자유롭게 선택가능하지만,
논문에서 선형적으로 값이 증가하는것보다는
코사인 확산 스케쥴이 좀 더 우수한 성능을 가졌다는것을 확인하였다고한다.

B_t가 B_1 = 0.0001에서 B_T = 0.02까지 선형적으로 증가하는 방식에서는
후기로 갈 수록 잡음이 더 많이 추가되는 방식이다

코사인 스케줄은 a_t_bar를 다음과 같이 정의한다
a_t_bar = cos((t/T) * (π/2))^2
그리고 삼각함수 항등식 cos(x)^2 + sin(x)^2 = 1에 따라
x_t는 다음과 같이 표현한다
x_t = cos((t/T) * (π/2)) * x_0 + sin((t/T) * (π/2)) * ε

추가로 초기에 잡음이 너무 적게 추가되는 일을 방지하기 위해 오프셋과 스케일링을 구현한다.

258페이지 까지의 코드는 diff_func에 있으니 한 번 찬찬히 주석을 달아봅시다

259p
역방향 확산 과정은 잡음 추가 과정을 되돌릴 수 있는 신경망 p_θ(x_t-1|x_t)이다.
이는 q의 근사라고 한다?
(q(x_t-1|x_t)의 역방향이라고하는데, x_t와 x_t-1의 위치가 잘못된것아닌가???)

N(0, I) 즉 다변량 표준 정규 분포에서
무작위 잡음을 샘플링해서 역방향 확산 과정을
여러번 적용하여 새로운 이미지를 생성할 수 있다고 한다.

Reverse diffusion process과 VAE의 decoder는 모두
신경망을 사용하여 랜덤한 잡음을 의미 있는 출력으로 변환하는 것이 목표이다.
따라서 VAE와 동일한 손실 함수를 사용한다고 한다

(둘의 차이는 VAE에만 정방향 과정(image to noise)이
학습가능한 모델의 일부이나
Diffusion 모델에는 parameter가 없다는것이다)
(??? 한 쪽은 잠재공간 아닙니까?,
VAE쪽은 가우시안 노이즈를 decoder해서 그런가?)

'동일한 손실 함수'가 뭔가 대체?
일단 chap3 VAE의 손실함수는
원본이미지와의 차이(를 cross entropy에 넣은)에,
KL 규제를 추가한것이다.

원본 DDPM 논문에서는 '손실함수의 정확한 형태를 유도'하고 -> ???
'타임스텝 t에서 이미지 x_0에 추가되는 잡음 ε를 예측하는'
신경망 ε_θ를 훈련하여 이를 최적화하는것을 보여준다
1. x_0를 샘플링하고
2. t번의 잡음 단계를 거쳐
3. 이미지 x_t = sqrt(a_t_bar) * x_0 + sqrt(1 - a_t_bar) * ε를 얻는다
4. x_t와 a_t_bar를 신경망에 전달하여
5. ε를 예측하여 ε_θ(x_t)를 구한다.
6. 이를 실제 ε와 비교하여 MSE(ε, ε_θ(x_t))를 구하고
7. 경사하강으로 학습한다.

무작위 샘플링 x_0을 구해
정방향 확산 과정을 여러번 거쳐
노이즈 비율 a_t_bar와, 잠음 추가가 끝난 x_t를 매개변수로
예측값 ε_θ(x_t)를 구하고
이를 정방향 확산 과정에서 나온
실제 ε 즉 다변량 표준 정규 분포의 값 입실론과 비교하여
손실함수 MSE의 값으로
패러미터를 경사하강하고 학습한다.

의문 1
입실론 값은 I에서 뽑는건가?

260p
확산 모델이 실제로는 두 개의 신경망 복사본을 유지한다고한다.
하나는 경사하강법으로 훈련된 신경망이고
다른 하나는 이전 훈련단계에서 훈련된 신경망 가중치의 지수이동 평균(EMA)를 사용하는 또 다른 신경망이다.

왜 그런짓을?
단기적인 변동과 등락에 영향을 받지 않으므로,
능동적으로 훈련된 신경망보다 더 안정적인 생성 작업을 수행한다고한다
따라서, 신경망으로 출력을 생성할 때 EMA 신경망을 쓴다고한다.

※ 지수 이동 평균이란? 최근 데이터에 더 높은 가중치를 두는 가중이동평균법의 일종
https://wikidocs.net/163553
EMA(i) = k * value(i) + (1 - k) * EMA(i-1)
k = 2/(N+1)
N은 이동평균의 탭수

261p
이런저런 요소들이 생략되어있지만, 전체 코드가 나와있다
작업 순서는

1. 이미지 배치를 평균이 0이고 단위 분산을 갖도록 정규화
2. 이미지 크기에 맞는 잡음을 샘플링
3. 랜덤 확산 시간을 샘플링
4. (코사인) 확산 스케줄에 따라 잡음과 신호 비율을 생성
5. 비율에 따른 잡음 이미지 생성
6. noise/signal_rates를 사용해 신경망이 잡음을 예측하고
   이를 사용해 잡음 이미지에서 잡음을 제거
7. 예측 잡음과 원본 잡음 사이의 손실을 손실함수에 넣고 오차를 계산
8. 경사하강
9. 기존 EMA와 훈련된 신경망의 값을 가중 평균하여 EMA 신경망 가중치 갱신

263p
U-Net은 stable diffusion의 backbone이다
책의 Diffusion 모델에도 사용하는듯
???
나중에 어느 부분에서 Transformer랑 연계되는지,
stable diffusion의 전체 구조는 어떠한지 알아보자

https://pasus.tistory.com/204
https://medium.com/@msmapark2/u-net-%EB%85%BC%EB%AC%B8-%EB%A6%AC%EB%B7%B0-u-net-convolutional-networks-for-biomedical-image-segmentation-456d6901b28a
책의 U-net 개념은 너무 부족하므로 관련 정보를 더 찾아보자

{
책의 기준으로
1-1 잡음의 분산[1, 1, 1]과 잡음 이미지[64, 64, 3]에서 시작한다
분산을 임베딩하여 [1, 1, 32] 텐서로 만들고
이를 업샘플링 하여 [64, 64, 32]만든다 -> ??? 업샘플링이 뭐냐
1-2 이미지는 합성곱으로 채널만 32로 하여 [64, 64, 32] 텐서로 만든다
1-3 이를 연결(concatenate)한다
}

U-Net은 다운샘플링과 업샘플링이 대칭을 이룬다
업샘플링: 채널 수를 줄이면서 표현을 공간적으로 확장
다운샘플링: 이미지를 공간적으로 압축하되 채널 방향으로 확장
???
잔차연결이 있긴한데 어디에서 어디로 연결되는지 정확히 알아보자
일단 저 'Block'들 당연히 한 개의 층으로 된것같지는 않게생겼다
263p 아래쪽부터 다시 시작

264p
U-Net은 입출력 크기가 같다고 함
해당 페이지에 12개의 단계가 존재하나 이를 이해하기 위해서는
잔차블럭, 사인파 임베딩, 다운블럭, 업블럭 4개의 개념이 U-Net에 적용된것을 확인가능

265p
사인파 임베딩
- 처음 소개된 것이 트랜스포머 알고리즘 논문인것으로 보아 위치 임베딩과 같은(유사한 것인듯하다)
- 아래 URL에서는 신경망의 parameter가 time(정황상 diffusion_times)간 공유되므로
t를 인코딩하기 위하여 sinusoidal positional embeddings를 사용했다고 한다.
NLP transformer의 위치 인코딩(임베딩) 서적에서는 단어의 위치를 모델에 전달하는 방법으로
(= 입력 시퀀스의 순서 정보를 보존하기위한 방법으로)
단어의 임베딩 벡터에 sin과 cos를 추가했다

책에서는 신경망의 후속 층에서 사용할 수 있는
스칼라 값을 더 복잡한 표현이 가능한
고차원 벡터로 변환하는 것이라고한다.
문장에서 단어의 이산적 위치를 벡터로 인코딩하는것에서
연속적인 값으로 확장하였다.

스칼라 값 x는 다음 방정식으로 인코딩된다.
γ(x) = (sin(2π * e^0f * x), ⋯,sin(2π * e^(L-1)f * x),cos(2π * e^0f * x), cos(2π * e^(L-1)f * x))
L은 원하는 임베딩 길이의 절반으로 선택, 책에서는 16
f는 ln(1000) / (L - 1)

사인파 임베딩을 만드는 코드는
하나의 잡음 분산에 대한 스칼라 값을
길이가 32인 벡터로 변환한다

코드에서 (L-1)f = ln(1000)
0/(L-1)부터 (L-1)/(L-1)까지 L개의 값과
ln(1000)을 곱한다.
이는 주기로 사용된다
2π와 e^freq와 분산x를 sin/cos에 넣고 2L만큼의 임베딩을 뽑아낸다

https://velog.io/@yeomjinseop/DDPM-%EA%B5%AC%ED%98%84%ED%95%98%EA%B8%B03

267p
잔차 블럭
내가 아는 그 Residual Connect 맞더라
배치 정규화로부터 시작
깊이를 늘리기 위해 합성곱(2개임)의 출력과 입력의 차만 계산,
출력과 비교할 때는 채널 수를 맞춰주기 위해 커널크기1인 합성곱 층을 한 번 통과

268p
다운블럭은 이미지 크기를 줄이면서(Pooling에서 줄어드는듯?), 채널 수를 늘린다
DownBlock은 depth 2의 잔차블럭으로 채널 수를 늘린다
(첫 다운 블럭은 32개로 오히려 줄어드나, 그냥 ResidualBlock으로 채널을 32->64->96으로 늘리긴함)
책의 다운블럭은 Residual block -> ResidualBlock -> AveragePooling2D 순서

업블럭은 이미지 크기를 늘리면서(이중 선형 보간), 채널 수를 줄인다
이중 선형 보간은 UpSampling2D 층에서 적용된다
업블럭은 bilear -> concat -> residual -> concat -> residual순서대로인데
concat층의 경우, 대응되는 downblock의 ResidualBlock 층의 출력 결과와 concat한다!!!
이 과정에서 U-Net을 가로지는 연결이 생긴다, 즉 DownBlock의 ResidualBlock층의 출력은 보존해놔야한다
concat 끝난 출력물에 대해서는 다음 ResidualBlock층에 넣고 채널 수를 맞춰주는 모양이다

270p까지 읽었음

271p
훈련된 모델에서 이미지를 샘플링 하려면 역방향 확산 과정을 적용
랜덤한 잡음에서 시작해서 꽃 그림이 남을 때까지 모델을 사용하여 잡음을 점진적으로 제거해야함

모델은 마지막 타임 스텝에서 추가된 잡음뿐만아니라
훈련셋의 이미지에 추가된 잡음의 총량을 예측하도록 훈련되는것이지만,
잡음을 한꺼번에 모두 제거할 수는 없다
완전한 랜덤한 잡음에서 한 번에 이미지를 예측하는것은 불가능하다고 한다.

정방향 과정을 모방하여
예측된 잡음을 여러 단계에 걸쳐
점진적으로 제거하여
모델이 자신의 예측에 적응하도록 하는 것이 좋다고한다.

의외로?? 실제 동작 자체는 x_t에서 x_0까지 잡음을 바로 예측한다.
x_0를 추정한다음, 예측된 잡음을 t-1스텝 까지만 적용해서 x_t-1를 생성한다
추가로 이 과정은 잡음 추가 단계랑 횟수가 같을 필요는 없다고한다

위 2단계의 과정은 x_t-1를 만들어 낸다
식도 있는데 좀 복합해서 항을 하나하나 풀어놔야겠다

{
정방향 확산 과정의 식은
x_t = sqrt(a_t_bar) * x_0 + sqrt(1 - a_t_bar) * ε
이를 x_0에 대해 정리하면
x_0 = (x_t - sqrt(1-a_t_bar) * ε) / sqrt(a_t_bar)
책의 '예측된' x_0항에서는 위와 완전히 같은식에, ε_θ(t, x_t)
※ 책의 표기는 (t)가 위첨자로, 세타가 아래첨자로, x_t는 소괄호안
ε_θ(t, x_t): 신경망 ε_θ으로 추정된 잡음에 비율이 곱해지기 전 원값

※ ϵ는 ε로 썼고, 둘 다 엡실론이라는 그리스 문자이며, 통계학에서 오차를 나타낸다고한다
254p는 ε에 대해 평균이 0이고 단위 분산을 갖는 표준 가우스 분포라고 설명한다
추측하건데 잡음에 비율이 곱해지기전 값을 의미하는듯, 이 값 자체는 다변량 표준 정규 분포에서 뽑은게 '맞고'
(x_t - sqrt(1-a_t_bar) * ε_θ(t, x_t))) / sqrt(a_t_bar) -> 이 값은 예측된 x_0이다

sqrt(a_t-1_bar) -> t-1단계의 신호의 비율이다

그렇다면 자연스럽게 잡음과 잡음비의 곱이 필요하나
생성 과정에 무작위성을 조절하기 위해 무작위 잡음을 추가한다

잡음비는 원래 sqrt(1-a_t-1_bar)일것을, sqrt(1-a_t-1_bar-σ_t^2)로 바꿔서 사용하고,
σ_t * ε_t는 무작위 가우스 잡음이며 새로 추가한다.
???
정규분포의 가법성에 의해 x_t-1도 정규분포를 따르는 모양
??????
ε_θ(t, x_t)가 노이즈역할인듯, 이또한 신경망ε_θ에서 나온것은 같을텐데
x_0를 예측하는데 사용한것이 왜 또 여기에... 코드를 한 번 봐야할 듯하다

전체 식은 x_t-1 = sqrt(a_t-1_bar)*((x_t-sqrt(1-a_t_bar)*ε_θ(t, x_t))/sqrt(a_t_bar)) + sqrt(1-a_t-1_bar-σ_t^2)*ε_θ(t, x_t) + σ_tε_t
σ_t = 0 인경우는 DDIM이며 잡음 제거 확산 암묵 모델이라 부르고
특수한 경우라 완전히 결정론적이므로
같은 잡음에 대해 같은 출력을 낸다
}

273p
단계2같은건 이해가 잘 안되는데 나중에 코드를 다시 읽???어보자